This project converts hand gestures into text and speech using computer vision and AI.
It detects hand movements from a camera, recognizes gestures, and outputs the corresponding text with voice.
Built for accessibility to help hearing- and speech-impaired individuals communicate easily.
Technologies used: Python, OpenCV, MediaPipe, and Text-to-SpeechÂ engine.
